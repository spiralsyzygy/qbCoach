# Session Log — Strategic Engine & GPT Layer Upgrade Backlog

**Session context**

* Game: Queen’s Blood (FF7 Rebirth)
* Session mode: live_coaching
* Coaching mode: strategic
* Opponent: Regina
* Date: 2025-12-13

This log captures *forward-looking engine and GPT-layer upgrade ideas* identified during live play. These are **not bugs**, but *modeling gaps* where stronger lookahead or heuristics would materially improve recommendations and coaching quality.

---

## 1. Deeper Effect Lookahead

**Observed issue**
The engine currently evaluates effects primarily at or near the current turn boundary. Effects whose *true value* emerges only after 1–2 enemy actions (e.g., delayed debuffs, destruction-triggered swings, positional denial) are undervalued in early placement decisions.

**Example symptom**

* High-impact cards (e.g., Archdragon) are recommended early for tempo even when their effect geometry would be substantially stronger if delayed until enemy commitment.

**Upgrade direction**

* Add limited-depth effect lookahead (1–2 plies) that evaluates *future-trigger probability*, not just immediate effect resolution.
* Weight effects by **expected future relevance**, not just immediate margin impact.

**Benefit**

* Reduces premature deployment of high-ceiling effect cards.
* Aligns engine outputs more closely with expert human timing instincts.

---

## 2. Delayed Value Modeling (Temporal Discounting)

**Observed issue**
The engine strongly prefers moves with immediate margin gains, even when those gains trade off against stronger delayed value or force unnecessary commitment.

**Example symptom**

* Turn 1 Archdragon preferred over Grasslands Wolf despite Wolf preserving future geometry and enabling higher midgame ceilings.

**Upgrade direction**

* Introduce a *temporal value curve* that allows certain resources to increase in value when delayed.
* Model opportunity cost of early commitment for cards with scaling or interaction potential.

**Benefit**

* More accurate prioritization between tempo plays vs setup plays.
* Fewer recommendations that are technically correct short-term but strategically inefficient long-term.

---

## 3. Geometry Preservation Heuristics

**Observed issue**
Current evaluation does not penalize plays that permanently consume high-flexibility geometry (central columns, multi-directional projection anchors) before opponent intent is revealed.

**Example symptom**

* Multi-projection cards are recommended into low-information positions where large portions of their pattern are unused.

**Upgrade direction**

* Track *geometry entropy*: how many future projection options remain after a move.
* Penalize early plays that reduce future placement optionality without forcing opponent response.

**Benefit**

* Encourages flexible openings.
* Produces recommendations that feel less “wasteful” to skilled players.

---

## 4. Pass / Inaction as Strategic Resource (Implemented)

**Observed issue (historical)**
Previously, the engine could not recommend pass, forcing suboptimal plays in winning positions.

**Status**

* PASS is now treated as a first-class action in the engine and CLI.

**Future extension**

* Allow the engine to model *inaction advantage* explicitly (e.g., forcing opponent commitment).

---

## 5. Heuristic Transparency for GPT Layer

**Observed issue**
When the engine prefers a move for non-obvious reasons (tempo denial, variance minimization), the GPT layer must infer intent indirectly.

**Upgrade direction**

* Surface heuristic tags in engine output, such as:

  * `tempo_denial`
  * `geometry_sacrifice`
  * `delayed_value_tradeoff`
* Allow GPT to explain *why* a move is preferred beyond raw margin.

**Benefit**

* Improves trust and clarity in coaching explanations.
* Helps users distinguish between engine certainty and heuristic bias.

---

## 6. Strategic Mode Awareness Improvements (GPT Layer)

**Observed issue**
Strategic coaching sometimes needs to acknowledge when a recommendation is *engine-optimal but human-controversial*.

**Upgrade direction**

* Add explicit GPT language patterns:

  * “Engine-optimal but geometry-inefficient”
  * “Low-variance line vs higher-ceiling alternative”

**Benefit**

* Better alignment between expert player intuition and engine guidance.
* Reduces friction when users question recommendations.

---

## 7. Inline Ambiguous Card Resolution During Commands (CLI / LiveSession)

**Observed issue**
The CLI already performs interactive disambiguation in *some* contexts (e.g., opening-hand entry can suggest close matches and ask for confirmation). However, during live gameplay commands like `enemy <name> <row> <col>` and `play <name> <row> <col>`, ambiguous or slightly misspelled card names currently cause a hard usage error, forcing the user to manually run `resolve` and then re-enter the original command.

A related but more subtle problem is that **suggestion prompts themselves interrupt gameplay flow**: the CLI prints a suggestion, but does not enter a confirmation state that can accept `y / n` (or a selection), so any follow-up input is treated as an unknown command.

**Example symptoms**

* *Opening hand*:

  * Misspelled input triggers a suggestion prompt and confirmation flow (y/n), then continues seamlessly.
* *Mid-play (enemy / play / draw)*:

  * `enemy crystalline crab bot 5` fails parsing; user must run `resolve crystalline crab` and then repeat `enemy 013 bot 5`.
  * `draw magic pot` prints `Did you mean: Magic Pot?` but entering `y` is rejected as an unknown command.
  * When multiple candidates are shown (e.g., `Grasslands Wolf, Grangalan`), there is **no way to select between them**; entering names, quotes, `y/n`, or `no` all fail, forcing a manual ID-based retry.

**Root cause (conceptual)**

* Suggestion output is *stateless*: the REPL does not transition into a temporary “awaiting resolution confirmation” mode.
* Because the engine already prints the suggestion, retyping the card name simply re-triggers the same ambiguity, creating a loop.

**Upgrade direction**

* Promote ambiguous-card handling to a **first-class interactive state**, not a one-off error message.
* Unify behavior across *all* card-accepting commands:

  * `play <id/name> <row> <col>`
  * `enemy <id/name> <row> <col>`
  * `draw <ids/names...>` (batch)
  * `set_hand <ids/names...>` (batch)

**Proposed UX (single-card token)**

1. On unknown or ambiguous card token, show candidates **with both name and ID**, e.g.:

   * `Did you mean: [1] Grasslands Wolf (008), [2] Grangalan (??? )?`
2. CLI enters a *resolution-confirmation state* tied to the original command.
3. Acceptable inputs while in this state:

   * `1`, `2`, … (explicit selection)
   * `y` (accept top suggestion)
   * `n` (cancel and retype)
4. On accept:

   * Substitute the resolved card ID into the original command
   * Execute it immediately
   * Return to the prior gameplay phase (no extra commands required)

**Batch tokens (e.g., draw / set_hand)**

* Resolve tokens left-to-right, entering confirmation state per ambiguous token.
* Deterministic ordering so logs and replays remain stable.

**Implementation notes**

* Reuse the existing resolver used for opening-hand sync.
* Store pending command + token index in CLI state until resolution completes.
* Ensure `resolve <token>` remains available as an explicit escape hatch.

**Benefit**

* Eliminates flow-breaking loops shown in real gameplay examples.
* Makes suggestion output actionable instead of informational-only.
* Keeps live coaching usable without forcing ID memorization.

---

## 8. Board State Desynchronization After Projection (Critical Investigation)

**Observed issue**
A board desync was observed beginning around **Turn 4** after playing **Levrikon at TOP-2**. The expected pawn projection into **TOP-3** did not appear in the engine-reported board state, while the live in-game board later reflected enemy ownership of TOP-3 after subsequent enemy play.

**Visual evidence (Turn 5)**
A Turn 5 in-game screenshot (FF7 Rebirth) confirms that **TOP-3 is enemy-owned (E1)** following Regina’s play of **Spearhawk @ TOP-4**. This contradicts the engine snapshot, which still showed TOP-3 as **neutral (N0) with an effect marker**.

**Confirmed live board facts from screenshot**

* TOP lane:

  * TOP-1: YOU-controlled (Grasslands Wolf)
  * TOP-2: YOU-controlled (Levrikon)
  * **TOP-3: ENEMY-controlled (E1 pawn present)**
  * TOP-4: ENEMY card (Spearhawk)

**Why this matters**

* Tile ownership affects legality, pawn propagation, effect scope, and downstream coaching.

**Priority**
Critical — correctness, legality, and trust-impacting.

---

## 9. Pawn Propagation Failure on Adjacent Placement (Critical)

**Observed issue**
A second, independent board desynchronization was observed on **Turn 6** involving **Security Officer @ BOT-1**. In the live FF7 board, playing Security Officer at BOT-1 should have increased the pawn rank of **BOT-2**, but the engine board did not apply this pawn propagation.

**Visual evidence (Turn 6)**
A Turn 6 in-game screenshot confirms:

* BOT-1: YOU-controlled (Security Officer)
* **BOT-2: Pawn rank increased in live game**
* Engine snapshot: BOT-2 pawn rank unchanged

**Symptoms (engine vs live)**

* Engine:

  * Security Officer correctly placed at BOT-1
  * BOT-2 pawn rank remained unchanged
* Live FF7:

  * BOT-2 pawn rank increased as expected from adjacent placement rules

**Why this matters**

* Pawn propagation is a **core rule mechanic**.
* Failure to apply it breaks:

  * rank math
  * lane scoring
  * legality and strength of future placements

**Hypotheses to investigate**

1. **Adjacency propagation bug**: pawn spread logic not firing for certain cards/tiles.
2. **Overwrite ordering issue**: propagation computed but overwritten later in the update cycle.
3. **Session desync amplification**: earlier desync (Section 8) may compound later propagation errors.

**Next steps / repro recipe**

* Minimal test:

  1. Fresh board
  2. Play Security Officer @ BOT-1
  3. Assert BOT-2 pawn rank increment
* Compare engine BoardState vs FF7 expected behavior.

**Priority**
Critical — core rules violation and compounding desync risk.

---

## Summary

This session highlighted a core truth:

> **The engine is already strong at tempo and threat suppression, but future strength lies in modeling restraint, timing, and optionality.**

The items above define a clear roadmap for improving both:

* **engine evaluation fidelity**, and
* **GPT-layer strategic coaching quality**.

This log should be referenced when planning Phase F+ / Phase H evolution.
